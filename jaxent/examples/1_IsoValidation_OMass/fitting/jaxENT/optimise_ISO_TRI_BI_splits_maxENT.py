"""
This script performs serial optimization sweeps across different maxent scaling values.

This uses the features generated by the 'featurise_ISO_TRI_BI.py' script.
This then loads the data splits generated by the 'splitdata_ISO.py' script.

This script is used to fit:
- ISO-Bi modal and ISO-Tri modal ensembles using maxent regularization with scaling values 1-10.
- The fitting is performed over convergence rates 1e-3 to 1e-10 using the optimise_sweep function.
- All runs are performed in serial (no multiprocessing).

Usage:
python optimise_maxent_sweep_serial.py --split-types all --ensemble ISO_TRI --loss-function mcMSE
python optimise_maxent_sweep_serial.py --split-types random,sequence --ensemble ISO_BI --loss-function MSE
python optimise_maxent_sweep_serial.py --maxent-range 1,5  # Only test maxent values 1-5
"""

import argparse
import os
import time
from typing import List

import jax
import jax.numpy as jnp

os.environ["XLA_PYTHON_CLIENT_PREALLOCATE"] = "false"

jax.config.update("jax_platform_name", "cpu")
os.environ["JAX_PLATFORM_NAME"] = "cpu"

# Import model components
from optimise_fn import run_optimise_ISO_TRI_BI_MAE

import jaxent.src.interfaces.topology as pt
from jaxent.src.custom_types.HDX import HDX_peptide
from jaxent.src.data.loader import ExpD_Dataloader
from jaxent.src.interfaces.simulation import Simulation_Parameters
from jaxent.src.models.config import BV_model_Config
from jaxent.src.models.core import Simulation
from jaxent.src.models.HDX.BV.features import BV_input_features
from jaxent.src.models.HDX.BV.forwardmodel import BV_model
from jaxent.src.utils.jit_fn import jit_Guard


def get_loss_function(loss_name: str):
    """Get loss function by name."""
    # Import inside function to avoid CUDA context issues
    from jaxent.src.opt.losses import (
        hdx_uptake_mean_centred_MSE_loss,
        hdx_uptake_MSE_loss,
    )

    losses = {"mcMSE": hdx_uptake_mean_centred_MSE_loss, "MSE": hdx_uptake_MSE_loss}
    if loss_name not in losses:
        raise ValueError(f"Unknown loss function: {loss_name}. Available: {list(losses.keys())}")
    return losses[loss_name]


def load_data_splits(datasplit_dir: str, split_type: str, num_splits: int) -> List[tuple]:
    """
    Load all data splits for a given split type.

    Args:
        datasplit_dir: Directory containing data splits
        split_type: Type of split (e.g., 'random', 'sequence')
        num_splits: Number of splits to load

    Returns:
        List of (train_data, val_data) tuples
    """
    splits = []
    split_type_dir = os.path.join(datasplit_dir, split_type)

    if not os.path.exists(split_type_dir):
        raise FileNotFoundError(f"Split type directory not found: {split_type_dir}")

    for split_idx in range(num_splits):
        split_path = os.path.join(split_type_dir, f"split_{split_idx:03d}")

        train_data = HDX_peptide.load_list_from_files(
            json_path=os.path.join(split_path, "train_topology.json"),
            csv_path=os.path.join(split_path, "train_dfrac.csv"),
        )
        val_data = HDX_peptide.load_list_from_files(
            json_path=os.path.join(split_path, "val_topology.json"),
            csv_path=os.path.join(split_path, "val_dfrac.csv"),
        )
        splits.append((train_data, val_data))

    return splits


def run_maxent_sweep(
    ensemble: str,
    loss_name: str,
    split_types_arg: str,
    maxent_values: List[float],
    n_steps: int = 10000,
    num_splits: int = 3,
) -> dict:
    """
    Run optimization sweep across different maxent scaling values in serial.

    Args:
        ensemble: Ensemble type (ISO_TRI or ISO_BI)
        loss_name: Loss function name (mcMSE or MSE)
        split_types_arg: Comma-separated split types or 'all'
        maxent_values: List of maxent scaling values to test
        n_steps: Number of optimization steps
        num_splits: Number of replicates per split type

    Returns:
        dict: Results summary
    """
    start_time = time.time()
    print(f"Starting maxent sweep for {ensemble}-{loss_name}")
    print(f"Maxent values: {maxent_values}")

    # Define convergence criteria
    convergence_rates = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]

    # Setup directories
    datasplit_dir = os.path.join(os.path.dirname(__file__), "_datasplits")
    features_dir = os.path.join(os.path.dirname(__file__), "_featurise")
    output_base_dir = os.path.join(os.path.dirname(__file__), "_optimise_maxent_MAEneps_adam")

    if not os.path.exists(datasplit_dir):
        raise FileNotFoundError(f"Datasplit directory not found: {datasplit_dir}")
    if not os.path.exists(features_dir):
        raise FileNotFoundError(f"Features directory not found: {features_dir}")

    os.makedirs(output_base_dir, exist_ok=True)

    # Load features for this ensemble
    feature_path = os.path.join(features_dir, f"features_{ensemble.lower()}.npz")
    topology_path = feature_path.replace("features_", "topology_").replace(".npz", ".json")

    features = BV_input_features.load(feature_path)
    feature_top = pt.PTSerialiser.load_list_from_json(topology_path)

    # Get loss function
    loss_function = get_loss_function(loss_name)

    # Setup BV model
    bv_config = BV_model_Config(num_timepoints=5)
    bv_config.timepoints = jnp.array([0.167, 1.0, 10.0, 60.0, 120.0])
    bv_model = BV_model(config=bv_config)
    model_parameters = bv_model.params

    # Discover split types
    split_types = [
        d
        for d in os.listdir(datasplit_dir)
        if os.path.isdir(os.path.join(datasplit_dir, d)) and d != "full_dataset"
    ]
    split_types.sort()

    # Filter split types if specified
    if split_types_arg != "all":
        requested = [s.strip() for s in split_types_arg.split(",")]
        split_types = [s for s in split_types if s in requested]
        if not split_types:
            raise ValueError(f"No valid split types selected from: {requested}")

    # Track results
    results = {
        "ensemble": ensemble,
        "loss_name": loss_name,
        "maxent_values": maxent_values,
        "split_types": split_types,
        "completed_runs": 0,
        "failed_runs": 0,
        "total_runs": len(split_types) * num_splits * len(maxent_values),
        "start_time": start_time,
        "run_details": [],
    }

    print(f"Processing {len(split_types)} split types with {num_splits} replicates each")
    print(f"Total runs: {results['total_runs']}")
    n_frames = features.features_shape[1]  # Assuming features.features_shape (n_residues, n_frames)

    parameters = Simulation_Parameters(
        frame_weights=jnp.ones(n_frames) / n_frames,
        frame_mask=jnp.ones(n_frames),
        model_parameters=(model_parameters,),
        forward_model_weights=jnp.ones(2),
        normalise_loss_functions=jnp.ones(2),
        forward_model_scaling=jnp.ones(2),
    )
    sim = Simulation(input_features=(features,), forward_models=(bv_model,), params=parameters)
    with jit_Guard(sim, cleanup_on_exit=True) as sim:
        sim.initialise()

        sim.forward(params=parameters)

        output_features = sim.outputs[0].y_pred()

    prior_HDX = []
    for idx, top in enumerate(feature_top):
        prior_HDX.append(
            HDX_peptide._create_from_features(topology=top, features=output_features[idx])
        )

    prior_dataset = ExpD_Dataloader(data=prior_HDX)
    prior_dataset.create_datasets(features=features, feature_topology=feature_top)

    # Process all combinations serially
    for split_type in split_types:
        print(f"\nProcessing split type: {split_type}")

        try:
            splits = load_data_splits(datasplit_dir, split_type, num_splits)
        except FileNotFoundError as e:
            print(f"Could not load splits for {split_type}. Skipping. Error: {e}")
            continue

        output_dir = os.path.join(output_base_dir, split_type)
        os.makedirs(output_dir, exist_ok=True)

        for split_idx, (train_data, val_data) in enumerate(splits):
            print(f"  Processing split {split_idx:03d}")
            print(f"    Train samples: {len(train_data)}, Val samples: {len(val_data)}")

            for maxent_value in maxent_values:
                run_name = f"{ensemble}_{loss_name}_{split_type}_split{split_idx:03d}_maxent{maxent_value:.1f}"

                print(f"    Running maxent={maxent_value:.1f}: {run_name}")
                run_start_time = time.time()

                try:
                    run_optimise_ISO_TRI_BI_MAE(
                        train_data=train_data,
                        val_data=val_data,
                        prior_data=prior_dataset,
                        features=features,
                        forward_model=bv_model,
                        model_parameters=model_parameters,
                        feature_top=feature_top,
                        convergence=convergence_rates,
                        loss_function=loss_function,
                        maxent_scaling=maxent_value,
                        n_steps=n_steps,
                        name=run_name,
                        output_dir=output_dir,
                    )

                    run_elapsed = time.time() - run_start_time
                    print(f"    ✓ Completed: {run_name} (Elapsed: {run_elapsed:.2f} s)")

                    results["completed_runs"] += 1
                    results["run_details"].append(
                        {
                            "split_type": split_type,
                            "split_idx": split_idx,
                            "maxent_value": maxent_value,
                            "status": "success",
                            "elapsed_time": run_elapsed,
                            "run_name": run_name,
                        }
                    )

                except Exception as e:
                    run_elapsed = time.time() - run_start_time
                    print(
                        f"    ✗ Failed: {run_name} - Error: {str(e)} (Elapsed: {run_elapsed:.2f} s)"
                    )
                    raise RuntimeError(f"Run failed for {run_name} with error: {str(e)}") from e

                    results["failed_runs"] += 1
                    results["run_details"].append(
                        {
                            "split_type": split_type,
                            "split_idx": split_idx,
                            "maxent_value": maxent_value,
                            "status": "failed",
                            "elapsed_time": run_elapsed,
                            "run_name": run_name,
                            "error": str(e),
                        }
                    )

    total_elapsed = time.time() - start_time
    results["total_elapsed"] = total_elapsed

    print(f"\n{'=' * 60}")
    print("Maxent sweep completed!")
    print(f"Successful runs: {results['completed_runs']}/{results['total_runs']}")
    print(f"Failed runs: {results['failed_runs']}")
    print(f"Success rate: {100 * results['completed_runs'] / results['total_runs']:.1f}%")
    print(f"Total elapsed time: {total_elapsed:.2f} s")

    # Print summary by maxent value
    print("\nSummary by maxent value:")
    for maxent_value in maxent_values:
        successful = sum(
            1
            for r in results["run_details"]
            if r["maxent_value"] == maxent_value and r["status"] == "success"
        )
        total = sum(1 for r in results["run_details"] if r["maxent_value"] == maxent_value)
        success_rate = 100 * successful / total if total > 0 else 0
        print(f"  Maxent {maxent_value:.1f}: {successful}/{total} runs ({success_rate:.1f}%)")

    return results


def run_all_combinations(
    split_types_arg: str,
    maxent_values: List[float],
    n_steps: int,
    num_splits: int,
) -> None:
    """Run maxent sweep for all ensemble-loss combinations."""
    ensembles = ["ISO_TRI", "ISO_BI"]

    loss_names = ["mcMSE", "MSE"]

    combinations = [(ensemble, loss_name) for ensemble in ensembles for loss_name in loss_names]

    print(f"Running maxent sweep for all {len(combinations)} combinations:")
    print(f"Combinations: {combinations}")
    print(f"Maxent values: {maxent_values}")
    print(f"Steps per run: {n_steps}")
    print(f"Replicates per split: {num_splits}")
    print("=" * 60)

    all_results = []
    total_start_time = time.time()

    for i, (ensemble, loss_name) in enumerate(combinations, 1):
        print(f"\n[{i}/{len(combinations)}] Running combination: {ensemble}-{loss_name}")
        print("-" * 40)

        try:
            result = run_maxent_sweep(
                ensemble=ensemble,
                loss_name=loss_name,
                split_types_arg=split_types_arg,
                maxent_values=maxent_values,
                n_steps=n_steps,
                num_splits=num_splits,
            )
            all_results.append(result)
            print(f"✓ Completed combination: {ensemble}-{loss_name}")

        except Exception as e:
            print(f"✗ Failed combination: {ensemble}-{loss_name} - Error: {str(e)}")
            continue

    total_elapsed = time.time() - total_start_time

    # Print overall summary
    print(f"\n{'=' * 60}")
    print("All combinations completed!")

    total_runs = sum(r["completed_runs"] + r["failed_runs"] for r in all_results)
    successful_runs = sum(r["completed_runs"] for r in all_results)
    failed_runs = sum(r["failed_runs"] for r in all_results)

    print(f"Total combinations processed: {len(all_results)}/{len(combinations)}")
    print(f"Total runs: {total_runs}")
    print(f"Successful runs: {successful_runs}")
    print(f"Failed runs: {failed_runs}")
    print(f"Success rate: {100 * successful_runs / total_runs:.1f}%")
    print(f"Total elapsed time: {total_elapsed:.2f} s")

    # Print per-combination summary
    print("\nPer-combination summary:")
    for result in all_results:
        success_rate = (
            100 * result["completed_runs"] / result["total_runs"] if result["total_runs"] > 0 else 0
        )
        print(
            f"  {result['ensemble']}-{result['loss_name']}: {result['completed_runs']}/{result['total_runs']} runs ({success_rate:.1f}%) in {result['total_elapsed']:.1f}s"
        )


def main():
    """Main function to run maxent sweep."""
    parser = argparse.ArgumentParser(description="Run maxent sweep for ISO_TRI/BI optimization.")
    parser.add_argument(
        "--ensemble",
        type=str,
        choices=["ISO_TRI", "ISO_BI"],
        help="Specific ensemble type to run (optional - if not provided, runs all combinations).",
    )
    parser.add_argument(
        "--loss-function",
        type=str,
        choices=["mcMSE", "MSE"],
        help="Specific loss function to use (optional - if not provided, runs all combinations).",
    )
    parser.add_argument(
        "--split-types",
        type=str,
        default="all",
        help="Comma-separated list of split types to run (e.g. 'random,sequence'). Use 'all' for all types.",
    )
    parser.add_argument(
        "--maxent-range",
        type=str,
        default="1,10",
        help="Range of maxent values as 'start,end' (inclusive). Default: '1,10'.",
    )
    parser.add_argument(
        "--n-steps",
        type=int,
        default=10000,
        help="Number of optimization steps per run (default: 10000).",
    )
    parser.add_argument(
        "--n-replicates",
        type=int,
        default=3,
        help="Number of replicates (splits) per split type (default: 3).",
    )

    args = parser.parse_args()

    # Parse maxent range
    try:
        start_val, end_val = map(int, args.maxent_range.split(","))
        maxent_values = list(range(start_val, end_val + 1))
    except ValueError:
        raise ValueError("maxent-range must be in format 'start,end' (e.g., '1,10')")

    # Check if specific combination is requested
    if args.ensemble is not None and args.loss_function is not None:
        # Single combination mode
        print("Running maxent sweep for specific combination:")
        print(f"  Ensemble: {args.ensemble}")
        print(f"  Loss function: {args.loss_function}")
        print(f"  Split types: {args.split_types}")
        print(f"  Maxent values: {maxent_values}")
        print(f"  Steps per run: {args.n_steps}")
        print(f"  Replicates per split: {args.n_replicates}")
        print("-" * 60)

        # Run the sweep for single combination
        results = run_maxent_sweep(
            ensemble=args.ensemble,
            loss_name=args.loss_function,
            split_types_arg=args.split_types,
            maxent_values=maxent_values,
            n_steps=args.n_steps,
            num_splits=args.n_replicates,
        )

    elif args.ensemble is None and args.loss_function is None:
        # All combinations mode
        run_all_combinations(
            split_types_arg=args.split_types,
            maxent_values=maxent_values,
            n_steps=args.n_steps,
            num_splits=args.n_replicates,
        )

    else:
        # Invalid - only one of ensemble/loss-function specified
        print(
            "Error: Either specify both --ensemble and --loss-function, or neither (to run all combinations)."
        )
        print("Examples:")
        print("  python optimise_maxent_sweep_serial.py  # Run all combinations")
        print(
            "  python optimise_maxent_sweep_serial.py --ensemble ISO_TRI --loss-function mcMSE  # Single combination"
        )
        return

    print(f"\nResults saved in: {os.path.join(os.path.dirname(__file__), '_optimise_maxent')}")


if __name__ == "__main__":
    main()
